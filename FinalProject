import random
from random import shuffle

class Room:
    def __init__(self, x=5):
        self.nrows = x
        self.ncols = x
        return
    
    
class RoomExplorer:
    def __init__(self, r):
        #initialize the room dimensions
        self.room = r
        #initialize the total cost
        self.cost = 0
        #initialize the number of visited cells
        self.visited = 0
        #initialize the policy
        self.policy = []
        for i in range(r.nrows):
            a=[]
            for j in range(r.ncols):
                a.append(-1)
            self.policy.append(a)
        return
    
    
    #explore a room and build a policy based on returned reward/punishment
    #new cell reward = 1
    #old cell reward = -1
    #bump into wall reward = -1
    def explore_room(self):
        #intial position = [1,0]
        x_p = 1
        y_p = 0
        
        total_reward = 1
        moves = {0:"∧", 1:"∨", 2:">", 3:"<", -1:"X"}
        
        while True:
            
            #get next move
            (move, reward) = self.get_next_move(x_p, y_p)
            print(x_p, y_p, ":", moves[move])
            
            #update policy and total reward
            self.policy[x_p][y_p] = move
            total_reward += reward
            
            
            #implement the move
            if move == 0: # up
                y_p += 1
            elif move == 1: #down
                y_p -= 1
            elif move == 2: #right
                x_p += 1
            elif move == 3: #left
                x_p -= 1
                
            #check for termination condition, if true, print policy & return total reward
            missing_moves=0
            for i in range(self.room.nrows):
                for j in range(self.room.ncols):
                   if  self.policy[i][j] == -1:
                       missing_moves += 1
                       
            if missing_moves == 1:
                print("Total Reward =", total_reward)
                print("Policy Learned:")
                for j in range(self.room.ncols-1,-1,-1):
                    for i in range(self.room.nrows):
                        print(moves[ self.policy[i][j]], end="\t")
                    print()
                return total_reward
            
        
    #get the next move to implement based on returned reward/punishment
    def get_next_move(self, x_p, y_p):
        #generate random move
        rand_move = [0, 1, 2, 3]
        shuffle(rand_move)
        
        bad_mvs_to_old_cells = []
        
        reward = -1
        move = -1
        for mv in rand_move:
            #calculate reward/punishment based on the reward of the reached cell
            if mv == 0:  #go up
                if y_p + 1 >= self.room.nrows or (x_p == 1 and y_p + 1 == 1):  #if bumping into wall or obstacle
                    reward = -1
                elif self.policy[x_p][y_p+1] >= 0:  #if old cell
                    reward = -1
                    bad_mvs_to_old_cells.append(mv)
                elif self.policy[x_p][y_p+1] == -1:  #if new cell
                    reward = 0
                    move = mv
                    break
            elif mv == 1:  #go down
                if y_p - 1 < 0 or (x_p == 1 and y_p - 1 == 1):  #if bumping into wall or obstacle
                    reward = -1
                elif self.policy[x_p][y_p-1] >= 0:  #if old cell
                    reward = -1
                    bad_mvs_to_old_cells.append(mv)
                elif self.policy[x_p][y_p-1] == -1:  #if new cell
                    reward = 0
                    move = mv
                    break
            #calculate reward/punishment based on the reward of the reached cell
            elif mv == 2:  #go right
                if x_p + 1 >= self.room.ncols or (x_p + 1 == 1 and y_p == 1):  #if bumping into wall or obstacle
                    reward = -1
                elif self.policy[x_p+1][y_p] >= 0:  #if old cell
                    reward = -1
                    bad_mvs_to_old_cells.append(mv)
                elif self.policy[x_p+1][y_p] == -1:  #if new cell
                    reward = 1
                    move = mv
                    break
            elif mv == 3:  #go left
                if x_p - 1 < 0 or (x_p - 1 == 1 and y_p == 1):  #if bumping into wall or obstacle
                    reward = -1
                elif self.policy[x_p-1][y_p] >= 0:  #if old cell
                    reward = -1
                    bad_mvs_to_old_cells.append(mv)
                elif self.policy[x_p-1][y_p] == -1:  #if new cell
                    reward = 1
                    move = mv
                    break
                    
        if move == -1:  #all moves are bad
            move = bad_mvs_to_old_cells[0]  #choose the move that will take you back to an old cell, don't choose a move that will bump you into a wall!
            reward = -1    
        
        return move, reward

#Main Code

room = Room(random.randint(3, 5))
count = 0   
while True:
    count += 1
    rx = RoomExplorer(room)
    total_reward = rx.explore_room()
    if(total_reward == 3 and room.nrows == 3 and room.ncols == 3):
        print("number of explorations performed to find optimal solution = ", count)
        break
    elif(total_reward == 6 and room.nrows == 4 and room.ncols == 4):
        print("number of explorations performed to find optimal solution = ", count)
        break
    elif(total_reward == 13 and room.nrows == 5 and room.ncols == 5):
        print("number of explorations performed to find optimal solution = ", count)
        break
